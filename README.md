# Neo4j CDC Sync on Azure

Real-time replication between two Neo4j Aura instances using Change Data Capture (CDC), Azure Event Hubs, and Kafka Connect.

```
Neo4j Aura (master, CDC-enabled)
    → Neo4j CDC Source Connector
        → Azure Event Hubs (Kafka API)
            → Neo4j CDC Sink Connector
                → Neo4j Aura (subscriber)
```

Kafka Connect runs on Azure Container Instance. The Docker image (with Neo4j Connector 5.2.0) is built and pushed to Azure Container Registry as part of the deploy.

All resources are co-located in the same Azure region as the Aura instances.

## Prerequisites

- [Terraform](https://developer.hashicorp.com/terraform/install) >= 1.5
- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) — authenticated via `az login`
- [Docker](https://docs.docker.com/get-docker/) — for building the Kafka Connect image
- [Neo4j Aura API credentials](https://console.neo4j.io) — Account > API Keys > Create New API Key
- Python 3.10+ (optional, for verification scripts)

## Deploy

```bash
cd terraform
cp terraform.tfvars.example terraform.tfvars
```

Edit `terraform.tfvars` and fill in your Aura API credentials:

```hcl
aura_client_id     = "your-client-id"
aura_client_secret = "your-client-secret"
aura_tenant_id     = "your-tenant-id"
```

Then deploy:

```bash
terraform init
terraform apply
```

This takes about 8 minutes. Terraform provisions two Aura instances, an Event Hubs namespace, a container registry, builds and pushes the Docker image, starts a Kafka Connect container, and deploys the source and sink connectors.

## Get credentials

Passwords are generated by Aura during provisioning. Terraform stores them in state and exposes them as outputs:

```bash
cd terraform

# Show everything (URIs, usernames, Event Hubs, Kafka Connect IP)
terraform output

# Show passwords (sensitive outputs require the -raw flag)
terraform output -raw master_neo4j_password
terraform output -raw subscriber_neo4j_password
```

## Verify

Check that both connectors are running:

```bash
KAFKA_CONNECT=$(terraform output -raw kafka_connect_rest_api)

curl -s $KAFKA_CONNECT/connectors/neo4j-master-publisher/status | jq '.connector.state, .tasks[0].state'
curl -s $KAFKA_CONNECT/connectors/neo4j-subscriber-consumer/status | jq '.connector.state, .tasks[0].state'
```

Both should report `"RUNNING"`.

Write a node to the master and check that it appears on the subscriber:

```bash
MASTER_URI=$(terraform output -raw master_neo4j_uri)
MASTER_PW=$(terraform output -raw master_neo4j_password)
SUB_URI=$(terraform output -raw subscriber_neo4j_uri)
SUB_PW=$(terraform output -raw subscriber_neo4j_password)

# Write to master
cypher-shell -a $MASTER_URI -u neo4j -p $MASTER_PW "CREATE (p:Person {name: 'Alice'})"

# Wait a few seconds, then check subscriber
sleep 10
cypher-shell -a $SUB_URI -u neo4j -p $SUB_PW "MATCH (p:Person {name: 'Alice'}) RETURN p"
```

## Tear down

```bash
cd terraform
terraform destroy
```

This removes all Azure and Aura resources. Cost while running is roughly $255/month ($8.50/day), so destroy after demos.

## Project structure

```
terraform/
  main.tf                     # Root module — orchestrates everything
  variables.tf                # All configurable parameters
  outputs.tf                  # Connection URIs, passwords, endpoints
  providers.tf                # AzureRM and Neo4j Aura providers
  terraform.tfvars.example    # Template for your credentials
  modules/
    aura-instance/            # Neo4j Aura provisioning
    event-hubs/               # Azure Event Hubs namespace + topics
    acr/                      # Container registry + Docker build/push
    aci/                      # Container instance + connector deployment

kafka-connect/
  Dockerfile                  # Custom image with Neo4j Connector 5.2.0

python/                       # Optional verification and test scripts
generators/                   # Optional sample data generators
```

## Secret scanning

This repo uses [gitleaks](https://github.com/gitleaks/gitleaks) to prevent accidentally committing secrets. Install the pre-commit hook before contributing:

```bash
brew install gitleaks pre-commit   # macOS
pre-commit install
```

Secrets are blocked at commit time. To scan manually:

```bash
gitleaks detect --source . --verbose
```

The `.gitignore` excludes `.env`, `*.tfvars`, `terraform.tfstate*`, and generated connector JSON files.

## Troubleshooting

**Connector shows FAILED**: Check the task trace for details:

```bash
curl -s $KAFKA_CONNECT/connectors/neo4j-master-publisher/tasks/0/status | jq '.trace'
```

A common cause is the source task timing out on topic metadata right after deploy. Restart it:

```bash
curl -X POST $KAFKA_CONNECT/connectors/neo4j-master-publisher/tasks/0/restart
```

**Aura region error**: The Aura provider expects region names like `eastus`, not `azure-eastus`. The `azure_region` variable in `variables.tf` is passed directly to both Azure and Aura resources.

**Docker image OS mismatch on Apple Silicon**: The Dockerfile builds with `--platform linux/amd64` to target Azure Container Instances.
