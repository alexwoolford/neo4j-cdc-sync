# Neo4j CDC Sync on Azure

Real-time replication between two Neo4j Aura instances using Change Data Capture (CDC), Azure Event Hubs, and Kafka Connect.

```
Neo4j Aura (master, CDC-enabled)
    → Neo4j CDC Source Connector
        → Azure Event Hubs (Kafka API)
            → Neo4j CDC Sink Connector
                → Neo4j Aura (subscriber)
```

Kafka Connect runs on Azure Container Instance. The Docker image (with Neo4j Connector 5.2.0) is built and pushed to Azure Container Registry as part of the deploy.

All resources are co-located in the same Azure region as the Aura instances.

## Prerequisites

- [Terraform](https://developer.hashicorp.com/terraform/install) >= 1.5
- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) — authenticated via `az login`
- [Docker](https://docs.docker.com/get-docker/) — for building the Kafka Connect image
- [Neo4j Aura API credentials](https://console.neo4j.io) — Account > API Keys > Create New API Key
- [Conda](https://docs.conda.io/en/latest/miniconda.html) or [Mamba](https://mamba.readthedocs.io/) — for Python environment

## Setup

Create and activate the conda environment:

```bash
conda env create -f environment.yml
conda activate neo4j-cdc-sync
```

This installs Python 3.11 and all required dependencies (neo4j driver, requests, rich).

## ⚠️ Security Warning

**This deployment exposes the Kafka Connect REST API (port 8083) publicly to the internet.**

### Acceptable Use
- ✅ Short-term demos and learning (< 1 day)
- ✅ Environments where you run `terraform destroy` immediately after testing

### NOT Acceptable
- ❌ Production systems
- ❌ Long-running deployments
- ❌ Systems handling sensitive data

### Why This Matters

The Kafka Connect REST API at port 8083 allows anyone who finds your IP to:
- Deploy malicious connectors to your cluster
- Read Event Hubs connection strings from connector configurations
- Potentially access your Neo4j instances if credentials are exposed in configs

### Mitigation

1. **Recommended for Demos**: Run `terraform destroy` immediately after your demo
2. **Basic Protection**: Implement IP whitelisting (requires ACI configuration changes)
3. **Production Setup**: Use Azure VNet integration with private endpoints (requires Premium Event Hubs)

**Bottom line:** This is safe for 1-day demos, but NOT for production or long-running systems.

## Deploy

### Quick Start (Recommended)

Use the automated deployment script with pre-flight checks:

```bash
# 1. Create terraform.tfvars from template
cd terraform
cp terraform.tfvars.example terraform.tfvars

# 2. Edit terraform.tfvars and add your Aura API credentials
#    Get credentials from: https://console.neo4j.io → Account → API Keys

# 3. Run deployment script
cd ..
./deploy.sh
```

The `deploy.sh` script will:
- ✓ Verify Azure CLI authentication
- ✓ Validate Python dependencies (rich, neo4j, requests, kafka-python)
- ✓ Check Terraform configuration
- ✓ Display security warning about port 8083
- ✓ Deploy infrastructure via Terraform
- ✓ Provide next steps

### Manual Deployment (Advanced)

If you prefer manual control:

```bash
# 1. Activate conda environment
conda activate neo4j-cdc-sync

# 2. Authenticate with Azure
az login

# 3. Configure and deploy
cd terraform
cp terraform.tfvars.example terraform.tfvars
# Edit terraform.tfvars with your credentials
terraform init
terraform apply
```

### Deployment Time

- Initial deployment: ~8 minutes
- Subsequent deployments (cached): ~3-4 minutes

Terraform provisions two Aura instances, an Event Hubs namespace with single-partition topic, a container registry, builds the Docker image in Azure, starts a Kafka Connect container, and deploys the source and sink connectors with automatic partition verification.

## Get credentials

Passwords are generated by Aura during provisioning. Terraform stores them in state and exposes them as outputs:

```bash
cd terraform

# Show everything (URIs, usernames, Event Hubs, Kafka Connect IP)
terraform output

# Show passwords (sensitive outputs require the -raw flag)
terraform output -raw master_neo4j_password
terraform output -raw subscriber_neo4j_password
```

## Verify

Check that both connectors are running:

```bash
KAFKA_CONNECT=$(terraform output -raw kafka_connect_rest_api)

curl -s $KAFKA_CONNECT/connectors/neo4j-master-publisher/status | jq '.connector.state, .tasks[0].state'
curl -s $KAFKA_CONNECT/connectors/neo4j-subscriber-consumer/status | jq '.connector.state, .tasks[0].state'
```

Both should report `"RUNNING"`.

Run the CDC test script to verify CREATE, UPDATE, and DELETE events propagate:

```bash
cd terraform
export MASTER_NEO4J_URI=$(terraform output -raw master_neo4j_uri)
export MASTER_NEO4J_PASSWORD=$(terraform output -raw master_neo4j_password)
export SUBSCRIBER_NEO4J_URI=$(terraform output -raw subscriber_neo4j_uri)
export SUBSCRIBER_NEO4J_PASSWORD=$(terraform output -raw subscriber_neo4j_password)
cd ../python
python test_live_cdc.py
```

This tests all CDC event types and reports actual propagation latency (typically 1-2 seconds).

## Demo flow (for presenting to users)

Use this sequence when demonstrating CDC to an audience.

**1. Set the scene**

- Two Neo4j Aura instances: a **master** (source of truth) and a **subscriber** (replica).
- Changes on the master are streamed in real time to the subscriber via CDC → Event Hubs → Kafka Connect.
- No polling or batch jobs; each write is captured and replicated as an event.

**2. Show the pipeline is running**

```bash
cd terraform
KAFKA_CONNECT=$(terraform output -raw kafka_connect_rest_api)
curl -s $KAFKA_CONNECT/connectors | jq .
curl -s $KAFKA_CONNECT/connectors/neo4j-master-publisher/status | jq '.connector.state, .tasks[0].state'
curl -s $KAFKA_CONNECT/connectors/neo4j-subscriber-consumer/status | jq '.connector.state, .tasks[0].state'
```

Both connectors should be `"RUNNING"`.

**3. Run the automated CDC test**

```bash
cd terraform
export MASTER_NEO4J_URI=$(terraform output -raw master_neo4j_uri)
export MASTER_NEO4J_PASSWORD=$(terraform output -raw master_neo4j_password)
export SUBSCRIBER_NEO4J_URI=$(terraform output -raw subscriber_neo4j_uri)
export SUBSCRIBER_NEO4J_PASSWORD=$(terraform output -raw subscriber_neo4j_password)
cd ../python
python test_live_cdc.py
```

- **Warm-up**: If the pipeline has been idle, the script waits for Event Hubs connections to come back (up to ~2 min). Tell the audience this is expected with Azure Event Hubs after idle.
- **Tests**: CREATE, UPDATE, and DELETE are run in sequence. Each step shows propagation time (typically under 2 seconds).

**4. Optional: show it live in the Aura consoles**

- Open the **master** instance in [Neo4j Aura Console](https://console.neo4j.io) and run a write, e.g. `CREATE (d:Demo {name: 'Live demo', at: datetime()})`.
- Open the **subscriber** instance and run `MATCH (d:Demo) RETURN d`. After a second or two, the node appears (with a `SourceEvent` label added by the sink).

**5. Wrap up**

- Emphasize: same graph model, real-time sync, no application code changes on the master; the subscriber is a read replica fed by CDC.
- Tear down when done: `cd terraform && terraform destroy` to avoid ongoing cost.

## Tear down

```bash
cd terraform
terraform destroy
```

This removes all Azure and Aura resources. Cost while running is roughly $255/month ($8.50/day), so destroy after demos.

## Project structure

```
terraform/
  main.tf                     # Root module — orchestrates everything
  variables.tf                # All configurable parameters
  outputs.tf                  # Connection URIs, passwords, endpoints
  providers.tf                # AzureRM and Neo4j Aura providers
  terraform.tfvars.example    # Template for your credentials
  modules/
    aura-instance/            # Neo4j Aura provisioning
    event-hubs/               # Azure Event Hubs namespace + topics
    acr/                      # Container registry + Docker build/push
    aci/                      # Container instance + connector deployment

kafka-connect/
  Dockerfile                  # Custom image with Neo4j Connector 5.2.0

python/                       # Optional verification and test scripts
generators/                   # Optional sample data generators
```

## Secret scanning

This repo uses [gitleaks](https://github.com/gitleaks/gitleaks) to prevent accidentally committing secrets. Install the pre-commit hook before contributing:

```bash
brew install gitleaks pre-commit   # macOS
pre-commit install
```

Secrets are blocked at commit time. To scan manually:

```bash
gitleaks detect --source . --verbose
```

The `.gitignore` excludes `.env`, `*.tfvars`, `terraform.tfstate*`, and generated connector JSON files.

## Troubleshooting

### Pre-Deployment Issues

**Error: "Azure CLI not authenticated"**
- Run: `az login`
- Verify: `az account show`

**Error: "Python dependencies missing"**
- Activate environment: `conda activate neo4j-cdc-sync`
- Or create it: `conda env create -f environment.yml`
- Verify: `python3 -c "import rich, neo4j, requests, kafka"`

**Error: "terraform.tfvars not found or incomplete"**
- Copy template: `cp terraform/terraform.tfvars.example terraform/terraform.tfvars`
- Edit and add your Aura API credentials from https://console.neo4j.io

**Error: "Docker daemon not running" (if using local builds)**
- Start Docker Desktop
- Verify: `docker info`
- Or switch to Azure-side builds (already configured with `az acr build`)

### Connector Issues

**Connector shows FAILED**

Check detailed error:
```bash
KAFKA_CONNECT=$(terraform output -raw kafka_connect_rest_api)
curl -s $KAFKA_CONNECT/connectors/neo4j-master-publisher/tasks/0/status | jq '.trace'
curl -s $KAFKA_CONNECT/connectors/neo4j-subscriber-consumer/tasks/0/status | jq '.trace'
```

Restart failed connector:
```bash
curl -X POST $KAFKA_CONNECT/connectors/neo4j-master-publisher/tasks/0/restart
```

**Source connector stuck in "STARTING"**

Event Hubs metadata timeout (known issue). Restart the task:
```bash
curl -X POST $KAFKA_CONNECT/connectors/neo4j-master-publisher/tasks/0/restart
```

The deploy script automatically restarts once, but you can manually restart if needed.

### CDC Sync Issues

**Relationships missing in subscriber (nodes replicate but relationships don't)**

This is the **multi-partition issue** — the most common CDC failure mode.

**Cause:** Event Hubs topic has >1 partition, breaking CDC ordering. Relationships arrive before their nodes, causing foreign key violations.

**Diagnosis:**
The `configure_connectors.py` script checks partition count automatically. If it warned during deployment, follow the fix below.

**Fix:**
```bash
# Option A: Delete topic in Azure Portal, then re-apply
# Azure Portal → Event Hubs → Your namespace → Event Hubs → cdc-all → Delete
cd terraform
terraform apply

# Option B: Destroy and recreate everything
cd terraform
terraform destroy
terraform apply
```

**Verify fix:**
```bash
cd python
python verify_cdc.py
```

**Slow propagation (>5 seconds per event)**

- Azure Event Hubs needs 1-2 minutes after idle to establish connections
- Run warmup: `python test_live_cdc.py` (includes automatic warm-up phase)
- Check connectors are RUNNING: `curl $KAFKA_CONNECT/connectors/neo4j-master-publisher/status`

**Sink connector error: "Node not found"**

This means relationships arrived before nodes (ordering violation):
- Verify topic has exactly 1 partition (see multi-partition fix above)
- Check source connector config has `topic.creation.default.partitions=1` (should be automatic)
- Restart connectors and clear data: `terraform destroy && terraform apply`

### Other Issues

**Aura region error: "Invalid region"**

The Aura provider expects region names like `eastus`, not `azure-eastus`. The `azure_region` variable in `variables.tf` is passed directly to both Azure and Aura resources.

**Docker image OS mismatch on Apple Silicon**

The image is now built in Azure using `az acr build`, which always produces linux/amd64 images compatible with Azure Container Instances.

**Python dependencies not found during Terraform run**

Make sure the conda environment is activated BEFORE running Terraform:
```bash
conda activate neo4j-cdc-sync
cd terraform
terraform apply
```

Or use the `./deploy.sh` script which checks this automatically.
